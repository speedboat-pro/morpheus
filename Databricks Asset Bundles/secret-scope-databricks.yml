%yaml
jobs:
  - name: my-job
    new_cluster:
      spark_version: "16.4.x-scala2.12"
      node_type_id: "i3.xlarge"
      num_workers: 2
    libraries:
      - jar: "dbfs:/path/to/your/jarfile.jar"
    spark_conf:
      "spark.databricks.secret.scope": "my-secret-scope"
      "spark.databricks.secret.key": "my-secret-key"
    tasks:
      - task_key: "my-task"
        notebook_task:
          notebook_path: "/path/to/your/notebook"